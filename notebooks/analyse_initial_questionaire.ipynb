{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Answered Questionaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "os.environ['OPENAI_API_KEY'] = config['openai_api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Each Question From Initial Questionnaire\n",
    "\n",
    "Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamfletcher/Documents/GitHub/ai_delphi_framework/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/analyse_each_question_from_initial_questionnaire.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you to the best of your ability analyse the responses from this question and answer set: {response}\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview') ## make this defined ones and used again and again!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What specific best practices would you recommend for data anonymization and encryption to maintain confidentiality in handling PII and sensitive IP information within the email triage process?\n",
      "What considerations would you take into account when assessing cloud vs. on-premise deployment options in relation to data security and operational efficiency for email triage?\n",
      "How valuable do you find developing interfaces for departmental staff to provide feedback on email triage accuracy to improve model performance in the context of user experience?\n",
      "In your opinion, how critical is ensuring the protection of Personally Identifiable Information (PII) and sensitive intellectual property (IP) within the machine learning lifecycle for email triage?\n",
      "How would you suggest incorporating mechanisms for continuous learning and adaptation to address evolving departmental categorization needs as new types of emails are received?\n",
      "How important is the selection of appropriate machine learning frameworks, programming languages, and tools that best fit the scalability, security, and performance requirements for email triage using AI?\n",
      "When designing machine learning models for processing millions of emails daily, what strategies do you believe are essential for ensuring scalability and high performance in categorization?\n",
      "How would you propose establishing clear governance structures for overseeing the deployment and ongoing management of the AI system within the email triage process?\n",
      "How would you ensure that the system enhances rather than complicates the workflow for employees managing emails during the triage process?\n",
      "What factors would you consider when evaluating long-term ROI and potential savings from reduced manual processing in the context of email triage using a machine learning model?\n",
      "How familiar are you with relevant data protection regulations such as GDPR and HIPAA, and how do you suggest ensuring compliance in the context of deploying a machine learning model for email triage?\n",
      "What ethical considerations do you believe are crucial when automating decisions based on categorization accuracy in email triage?\n",
      "How important is seamless integration of the machine learning model into existing email and IT infrastructure without operational disruptions in deploying a model for email triage?\n",
      "What are your recommendations for training machine learning models with diverse datasets to recognize a wide array of email requests effectively in the context of email triage?\n",
      "How significant do you consider the impact of potential biases in the model on the email triage process, and what measures would you recommend to address biases and ensure accurate categorization?\n",
      "What strategies would you recommend for aligning the machine learning deployment with business objectives and departmental needs through collaboration and stakeholder engagement in the context of email triage?\n",
      "In your opinion, how critical is evaluating the cost implications of developing, deploying, and maintaining the machine learning system against the benefits of increased efficiency and accuracy in email triage?\n",
      "How would you approach scaling the model's capacity as email volume increases or as new types of requests emerge to maintain accuracy in email categorization?\n",
      "How crucial do you believe stakeholder engagement is in the successful deployment of a machine learning model for email triage, and how would you foster collaboration between IT, data science teams, and departmental staff?\n",
      "What level of importance do you place on understanding and adhering to regulations governing the use of AI and machine learning in processing communications containing sensitive information for email triage?\n",
      "What strategies would you propose for deploying the model to allow for easy updates and maintenance while ensuring uninterrupted email triage operations?\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('outputs/8_formatted_questions/*.md')\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        print(os.path.basename(file).replace('.md',''))\n",
    "        response = f.read()\n",
    "        analysed_questionaire = llm.invoke(chat_template.format_messages(response=response)).content\n",
    "\n",
    "        with open(f\"outputs/9_analysed_questions/{os.path.basename(file).replace('.md','')}.md\", \"w\") as text_file:\n",
    "            text_file.write(analysed_questionaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Analyses into a Full Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('outputs/9_analysed_questions/*.md')\n",
    "text_lines = []\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        question = os.path.basename(file).replace('.md','')\n",
    "        # print(question)\n",
    "        response = f.read()\n",
    "        line = f\"\"\"## {question}\n",
    "\n",
    "        {response}\n",
    "\n",
    "\"\"\"\n",
    "    text_lines.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Inital Analysis into Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/convert_initial_analysis_into_summary.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you to the best of your ability summarise the analyses around the follow questions: {text_lines}\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview') ## make this defined ones and used again and again!!\n",
    "grand_summary = llm.invoke(chat_template.format_messages(text_lines=text_lines)).content\n",
    "\n",
    "with open(\"outputs/10_grand_summary.md\", \"w\") as text_file:\n",
    "    text_file.write(grand_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: now grab follow up questions from 9_analysis and create a new questionaire to ask the experts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

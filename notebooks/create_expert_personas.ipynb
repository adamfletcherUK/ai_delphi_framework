{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Expert Personas to Answer Initial Questionaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "os.environ['OPENAI_API_KEY'] = config['openai_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/1_question.md\", \"r\") as f:\n",
    "    question = f.read()\n",
    "\n",
    "with open(\"outputs/2_key_themes.md\", \"r\") as f:\n",
    "    key_themes = f.read()\n",
    "\n",
    "with open(\"outputs/3_questionnaire.md\", \"r\") as f:\n",
    "    questionare = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an Initial Overview of Expert Types\n",
    "\n",
    "\n",
    "the types of experts we might need -- give a high level overview of the experts we might need.\n",
    "This is needed as ChatGPT cannot make all detailed personas at once - we need to upramp the amount of text made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/make_initial_overview_of_expert_types.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"can you craft descriptions of the different type of experts which would make up a diverse panel of experts on the subject of '{question}', with the key themes being '{key_themes}' where the questions being answered are '{questionare}'\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview') ## make this defined ones and used again and again!!\n",
    "expert_personas_overview_md = llm.invoke(chat_template.format_messages(\n",
    "    question=question, key_themes=key_themes, questionare=questionare)).content\n",
    "\n",
    "with open(\"outputs/4_expert_personas_overview.md\", \"w\") as text_file:\n",
    "    text_file.write(expert_personas_overview_md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Initial Overview to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/convert_initial_overview_to_JSON.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you convert the following into a JSON object: {expert_personas_overview_md}\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI() ## make this defined ones and used again and again!!\n",
    "expert_personas_overview_json = llm.invoke(chat_template.format_messages(\n",
    "    expert_personas_overview_md=expert_personas_overview_md)).content\n",
    "\n",
    "\n",
    "persona_overview_json = json.loads(expert_personas_overview_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craft Expert Persona Descriptions from Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/craft_persona_from_overview_persona.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you convert craft various LLM personas for the role of {role}, with the characteristics of {characteristics}. \n",
    "            Which could suitably answer the question of '{question}', where the key themes are '{key_themes}' and the questions being asked are '{questionare}'\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Engineers\n",
      "Data Privacy and Security Specialists\n",
      "IT Infrastructure Architects\n",
      "Ethics and Bias Reduction Experts\n",
      "User Experience (UX) Designers\n",
      "Regulatory Compliance Consultants\n",
      "Business Analysts and ROI Experts\n",
      "Cloud Computing and Deployment Specialists\n",
      "Stakeholder Engagement Coordinators\n",
      "Industry Veterans\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('outputs/5_custom_personas/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "for i in persona_overview_json['Expert Personas']:\n",
    "    print(i['Role'])\n",
    "    specific_personas = llm.invoke(chat_template.format_messages(\n",
    "    role=i['Role'], \n",
    "    characteristics=i['characteristics'], \n",
    "    question=question, key_themes=key_themes, questionare=questionare)).content\n",
    "\n",
    "    with open(f\"outputs/5_custom_personas/{i['Role']}.txt\", \"w\") as text_file:\n",
    "        text_file.write(specific_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Expert Persona Descriptions to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regulatory Compliance Consultants\n",
      "Business Analysts and ROI Experts\n",
      "Cloud Computing and Deployment Specialists\n",
      "Stakeholder Engagement Coordinators\n",
      "Ethics and Bias Reduction Experts\n",
      "Data Privacy and Security Specialists\n",
      "Industry Veterans\n",
      "User Experience (UX) Designers\n",
      "Machine Learning Engineers\n",
      "IT Infrastructure Architects\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/convert_expert_persona_descriptions_to_JSON.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you convert the following into a JSON object: {specific_personas}\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# with open(\"outputs/specific_personas.txt\", \"r\") as text_file:\n",
    "#     specific_personas = text_file.read()\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview') ## make this defined ones and used again and again!!\n",
    "\n",
    "\n",
    "files = glob.glob('outputs/5_custom_personas/*.txt')\n",
    "for file in files:\n",
    "    print(os.path.basename(file).replace('.txt',''))\n",
    "    with open(file, 'r') as text_file:\n",
    "        specific_personas = text_file.read()\n",
    "\n",
    "\n",
    "    specific_personas_json = llm.invoke(chat_template.format_messages(\n",
    "        specific_personas=specific_personas)).content\n",
    "\n",
    "\n",
    "    specific_personas_json = json.loads(specific_personas_json)\n",
    "    with open(f\"outputs/5_custom_personas/{os.path.basename(file).replace('.txt','')}.json\", 'w') as f:\n",
    "        json.dump(specific_personas_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flesh Out Expert Personas with Viewpoints\n",
    "\n",
    "This step adds different viewpoints, beliefs and behavioural characteristsics to personas in order to get different perspectives on the questionnaire with the same expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(open('./persona_descriptions/flesh_out_expert_personas_with_viewpoints.txt').read())\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"\"\"Can you convert craft a detailed personas for the role of {role}, with the characteristics of {characteristics}. \n",
    "            Which could suitably answer questions where the key themes are '{key_themes}'\"\"\"\n",
    "            ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview') ## make this defined ones and used again and again!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Computing and Deployment Specialists\n",
      "  -  Cloud Architect: The Strategic Visionary\n",
      "  -  Data Privacy and Security Specialist: The Guardian\n",
      "  -  Machine Learning Deployment Engineer: The Pragmatist\n",
      "  -  Ethical AI Advocate: The Conscientious\n",
      "  -  Stakeholder Engagement Facilitator: The Collaborator\n",
      "Data Privacy and Security Specialists\n",
      "  -  Data Privacy Guardian\n",
      "  -  Scalability Architect\n",
      "  -  AI Compliance Strategist\n",
      "  -  Machine Learning Ethicist\n",
      "  -  Continuous Learning Innovator\n",
      "  -  Deployment Efficiency Expert\n",
      "Stakeholder Engagement Coordinators\n",
      "  -  The Integrator\n",
      "  -  The Technophile\n",
      "  -  The Guardian\n",
      "Machine Learning Engineers\n",
      "  -  The Data Guardian\n",
      "  -  The Scalability Architect\n",
      "  -  The Continuous Learner\n",
      "  -  The Integration Expert\n",
      "  -  The Ethical Innovator\n",
      "Industry Veterans\n",
      "  -  The Seasoned Strategist\n",
      "  -  The Tech-Savvy Innovator\n",
      "  -  The Data Protection Guardian\n",
      "  -  The Process Optimization Expert\n",
      "IT Infrastructure Architects\n",
      "  -  The Data Guardian\n",
      "  -  The Scalability Strategist\n",
      "  -  The Integration Innovator\n",
      "  -  The Ethical AI Advocate\n",
      "  -  The Collaborative Facilitator\n",
      "User Experience (UX) Designers\n",
      "  -  UX Designer for AI Systems Interface Persona: The Intuitive Architect\n",
      "  -  UX Designer for Feedback Systems Persona: The Feedback Strategist\n",
      "  -  UX Designer for Workflow Enhancement Persona: The Efficiency Expert\n",
      "Ethics and Bias Reduction Experts\n",
      "  -  The Data Guardian\n",
      "  -  The Bias Buster\n",
      "  -  The Ethical Architect\n",
      "  -  The Compliance Conductor\n",
      "  -  The Scalability Strategist\n",
      "Business Analysts and ROI Experts\n",
      "  -  The Strategic Optimizer\n",
      "  -  The Efficiency Explorer\n",
      "  -  The Data Guardian\n",
      "  -  The Cloud Innovator\n",
      "Regulatory Compliance Consultants\n",
      "  -  The Data Guardian\n",
      "  -  The AI Ethicist\n",
      "  -  The Techno-Strategist\n",
      "  -  The Governance Guru\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('outputs/6_final_personas/*.md')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob('outputs/5_custom_personas/*.json')\n",
    "for file in files:\n",
    "    print(os.path.basename(file).replace('.json',''))\n",
    "    with open(file, 'r') as j:\n",
    "        specific_personas_json = json.loads(j.read())\n",
    "\n",
    "    for i in specific_personas_json['Expert Personas']:\n",
    "        print(f\"  -  {i['Role']}\")\n",
    "        detailed_persona = llm.invoke(chat_template.format_messages(\n",
    "            role=i['Role'], \n",
    "            characteristics=i['characteristics'], \n",
    "            question=question, key_themes=key_themes, questionare=questionare)).content\n",
    "\n",
    "        with open(f\"outputs/6_final_personas/{os.path.basename(file).replace('.json','')} {i['Role'].replace(':', '')}.md\", \"w\") as text_file:\n",
    "            text_file.write(detailed_persona)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
